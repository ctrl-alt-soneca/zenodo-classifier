{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import sklearn\n",
    "import requests\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from __future__ import division\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tarfile\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"./data/zenodo_open_metadata_06_04_2017_cleaned_20_08_17.json\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "labels = [d['spam'] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feat_tr(d):\n",
    "    return d['description'] + d['title']\n",
    "\n",
    "X = [feat_tr(d) for d in data]\n",
    "y = np.array([[1 if d['spam'] else 0, 1 if not d['spam'] else 0] for d in data])\n",
    "\n",
    "ngram_range=(1, 1)\n",
    "count_vect = CountVectorizer(ngram_range=ngram_range, max_features=8000)\n",
    "tfid = TfidfTransformer()\n",
    "X_v = count_vect.fit_transform(X)\n",
    "X_v = tfid.fit_transform(X_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X_v, np.asarray(y, dtype=np.float32), test_size=3000, train_size=6000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#trX_idx, tsX_idx, trY_idx, tsY_idx = train_test_split(range(X_v.shape[0]),range(X_v.shape[0]), test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX, testX, trainY, testY = train_test_split(X_v, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainX = np.asarray(trainX.todense(), dtype=np.float32)\n",
    "#trainY = trainY\n",
    "testX = np.asarray(testX.todense(), dtype=np.float32)\n",
    "#testY = testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numFeatures = trainX.shape[1]\n",
    "numLabels = trainY.shape[1]\n",
    "numEpochs = 27000\n",
    "# a smarter learning rate for gradientOptimizer\n",
    "learningRate = tf.train.exponential_decay(learning_rate=0.0008,\n",
    "                                          global_step= 1,\n",
    "                                          decay_steps=trainX.shape[0],\n",
    "                                          decay_rate= 0.95,\n",
    "                                          staircase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X = X-matrix / feature-matrix / data-matrix... It's a tensor to hold our email\n",
    "# data. 'None' here means that we can hold any number of emails\n",
    "Xtens = tf.placeholder(tf.float32, [None, numFeatures])\n",
    "# yGold = Y-matrix / label-matrix / labels... This will be our correct answers\n",
    "# matrix. Every row has either [1,0] for SPAM or [0,1] for HAM. 'None' here \n",
    "# means that we can hold any number of emails\n",
    "yGold = tf.placeholder(tf.float32, [None, numLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Values are randomly sampled from a Gaussian with a standard deviation of:\n",
    "#     sqrt(6 / (numInputNodes + numOutputNodes + 1))\n",
    "\n",
    "weights = tf.Variable(tf.random_normal([numFeatures,numLabels],\n",
    "                                       mean=0,\n",
    "                                       stddev=(np.sqrt(6/numFeatures+\n",
    "                                                         numLabels+1)),\n",
    "                                       name=\"weights\"))\n",
    "\n",
    "bias = tf.Variable(tf.random_normal([1,numLabels],\n",
    "                                    mean=0,\n",
    "                                    stddev=(np.sqrt(6/numFeatures+numLabels+1)),\n",
    "                                    name=\"bias\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INITIALIZE our weights and biases\n",
    "init_OP = tf.initialize_all_variables()\n",
    "\n",
    "# PREDICTION ALGORITHM i.e. FEEDFORWARD ALGORITHM\n",
    "apply_weights_OP = tf.matmul(Xtens, weights, name=\"apply_weights\")\n",
    "add_bias_OP = tf.add(apply_weights_OP, bias, name=\"add_bias\") \n",
    "activation_OP = tf.nn.sigmoid(add_bias_OP, name=\"activation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost_OP = tf.nn.l2_loss(activation_OP-yGold, name=\"squared_error_cost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_OP = tf.train.GradientDescentOptimizer(learningRate).minimize(cost_OP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_values=[]\n",
    "accuracy_values=[]\n",
    "cost_values=[]\n",
    "# Turn on interactive plotting\n",
    "plt.ion()\n",
    "# Create the main, super plot\n",
    "fig = plt.figure()\n",
    "# Create two subplots on their own axes and give titles\n",
    "ax1 = plt.subplot(\"211\")\n",
    "ax1.set_title(\"TRAINING ACCURACY\", fontsize=18)\n",
    "ax2 = plt.subplot(\"212\")\n",
    "ax2.set_title(\"TRAINING COST\", fontsize=18)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "### RUN THE GRAPH ###\n",
    "#####################\n",
    "\n",
    "# Create a tensorflow session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize all tensorflow variables\n",
    "sess.run(init_OP)\n",
    "\n",
    "## Ops for vizualization\n",
    "# argmax(activation_OP, 1) gives the label our model thought was most likely\n",
    "# argmax(yGold, 1) is the correct label\n",
    "correct_predictions_OP = tf.equal(tf.argmax(activation_OP,1),tf.argmax(yGold,1))\n",
    "# False is 0 and True is 1, what was our average?\n",
    "accuracy_OP = tf.reduce_mean(tf.cast(correct_predictions_OP, \"float\"))\n",
    "# Summary op for regression output\n",
    "activation_summary_OP = tf.summary.histogram(\"output\", activation_OP)\n",
    "# Summary op for accuracy\n",
    "accuracy_summary_OP = tf.summary.scalar(\"accuracy\", accuracy_OP)\n",
    "# Summary op for cost\n",
    "cost_summary_OP = tf.summary.scalar(\"cost\", cost_OP)\n",
    "# Summary ops to check how variables (W, b) are updating after each iteration\n",
    "weightSummary = tf.summary.histogram(\"weights\", weights.eval(session=sess))\n",
    "biasSummary = tf.summary.histogram(\"biases\", bias.eval(session=sess))\n",
    "# Merge all summaries\n",
    "all_summary_OPS = tf.summary.merge_all()\n",
    "# Summary writer\n",
    "writer = tf.summary.FileWriter(\"summary_logs\", sess.graph)\n",
    "\n",
    "# Initialize reporting variables\n",
    "cost = 0\n",
    "diff = 1\n",
    "\n",
    "# Training epochs\n",
    "for i in range(numEpochs):\n",
    "    if i > 1 and diff < .0001:\n",
    "        print(\"change in cost %g; convergence.\"%diff)\n",
    "        break\n",
    "    else:\n",
    "        # Run training step\n",
    "        step = sess.run(training_OP, feed_dict={Xtens: trainX, yGold: trainY})\n",
    "        # Report occasional stats\n",
    "        if i % 10 == 0:\n",
    "            # Add epoch to epoch_values\n",
    "            epoch_values.append(i)\n",
    "            # Generate accuracy stats on test data\n",
    "            summary_results, train_accuracy, newCost = sess.run(\n",
    "                [all_summary_OPS, accuracy_OP, cost_OP], \n",
    "                feed_dict={Xtens: trainX, yGold: trainY}\n",
    "            )\n",
    "            # Add accuracy to live graphing variable\n",
    "            accuracy_values.append(train_accuracy)\n",
    "            # Add cost to live graphing variable\n",
    "            cost_values.append(newCost)\n",
    "            # Write summary stats to writer\n",
    "            writer.add_summary(summary_results, i)\n",
    "            # Re-assign values for variables\n",
    "            diff = abs(newCost - cost)\n",
    "            cost = newCost\n",
    "\n",
    "            #generate print statements\n",
    "            print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            print(\"step %d, cost %g\"%(i, newCost))\n",
    "            print(\"step %d, change in cost %g\"%(i, diff))\n",
    "            \n",
    "            y_res = sess.run(activation_OP, feed_dict={Xtens:testX})\n",
    "            y_res = list(y_res[:,0] > 0.5)\n",
    "            y_gold = list(bool(yy) for yy in testY[:,0])\n",
    "            acc = [(ref, pred) for ref, pred in zip(y_gold, y_res)]\n",
    "            c = Counter(acc)\n",
    "            print(c)\n",
    "            print(\"S->S:{0:.5f}   H->H:{1:.5f}   Acc:{2:.5f}\".format(\n",
    "                c[(True, True)] / (c[(True, True)] + c[(True, False)]),\n",
    "                c[(False, False)] / (c[(False, False)] + c[(False, True)]),\n",
    "                (c[(False, False)] + c[(True, True)]) / (len(acc))\n",
    "            ))\n",
    "\n",
    "            # Plot progress to our two subplots\n",
    "            #accuracyLine, = ax1.plot(epoch_values, accuracy_values)\n",
    "            #costLine, = ax2.plot(epoch_values, cost_values)\n",
    "            #fig.canvas.draw()\n",
    "            #time.sleep(1)\n",
    "\n",
    "\n",
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={Xtens: testX, \n",
    "                                                                yGold: testY})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well do we perform on held-out test data?\n",
    "print(\"final accuracy on test set: %s\" %str(sess.run(accuracy_OP, \n",
    "                                                     feed_dict={Xtens: testX,\n",
    "                                                                yGold: testY})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_res = sess.run(activation_OP, feed_dict={Xtens:testX})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_res = list(y_res[:,0] > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_gold = list(bool(yy) for yy in testY[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [(ref, pred) for ref, pred in zip(y_gold, y_res)]\n",
    "c = Counter(acc)\n",
    "print(\"S->S:{0:.5f}   H->H:{1:.5f}   Acc:{2:.5f}\".format(\n",
    "    c[(True, True)] / (c[(True, True)] + c[(True, False)]),\n",
    "    c[(False, False)] / (c[(False, False)] + c[(False, True)]),\n",
    "    (c[(False, False)] + c[(True, True)]) / (len(acc))\n",
    "))\n",
    "print(c)\n",
    "print(\"Spam->Spam: {0:.4f}\".format(c[(True, True)] / (c[(True, True)] + c[(True, False)])))\n",
    "print(\"Ham -> Ham: {0:.4f}\".format(c[(False, False)] / (c[(False, False)] + c[(False, True)])))\n",
    "print(\"Accuracy: {0:.4f}\".format((c[(False, False)] + c[(True, True)] ) / (len(acc))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc = [idx for ref, pred, idx in zip(y_gold, y_res, tsX_idx) if (ref, pred) == (False, True)]\n",
    "spammy_stuff = [(data[idx]['recid'], data[idx]['description']) for idx in acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spammy_stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Saver\n",
    "saver = tf.train.Saver()\n",
    "# Save variables to .ckpt file\n",
    "saver.save(sess, \"trained_variables.ckpt\")\n",
    "\n",
    "# Close tensorflow session\n",
    "#sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (classifier)",
   "language": "python",
   "name": "classifier"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}